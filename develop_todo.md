# 性能改进

- [ ] 使用异步队列处理 LLM 翻译，避免阻塞

# 效果改进

- [ ] 看起来干扰严重的情况下短音频转录事件太多，导致幻觉增多 + 队列堆积，也许还是需要在转录之前进行初筛【看起来基于时间的分割不太合理，还是要依赖 VAD 的结果】【看起来 `if audio_buffer.n_samples() - cont_non_speech >= 5000:` 效果不错】
- [ ] 添加 `initial_prompt` 以提高转录精度 [NEXT]
- [ ] 翻译可选携带上下文 [NEXT]
- [ ] 研究为什么有时候会丢句（是 whisper 的 non-speech 阈值问题吗？），对当前的启发式算法进行进一步研究和改进
- [ ] 探究 LLM 对于混合语言的支持（例如 Gemini），并研究微调的可能性
- [ ] 在足够长的静音时重置所有模型、迭代器的状态
- [ ] 抄一下[这里](https://github.com/ionic-bond/stream-translator-gpt/blob/04b69eb0f3fa8ad3fab6b79a95645a9a0058ba5f/stream_translator_gpt/filters.py#L10) 的过滤器

# 功能改进

- [ ] 增加 YouTube 的直播流获取功能
- [ ] 增加延迟监控
- [ ] 增加歌段检测，避免转录翻译
- [ ] 研究 Bilibili / YouTube 的各种直播流的延迟并选择最佳的直播流
- [ ] 实验并增加 Azure 语音识别后端 [NEXT]
- [ ] 增加 SenseVoice (Small) 作为转录后端，提供低开销选择 [NEXT]
- [x] 增加 Gemini 作为转录后端代替 [DONE 2025/01/18]
    - [ ] 看起来 Gemini 转录有时候会输出无关内容，应当想办法加以过滤
- [x] 增加 OpenAI Whisper 及其兼容 API 作为转录后端代替（无显卡的情况下）[DONE 2025/01/15]

# 开发优化

- [ ] 增加音频相关方便调试的工具

# 错误修复

- [x] 应使用应用层缓冲，而不是使用系统管道缓冲，因为系统管道缓冲的容量有限

--------------------------------------------------

1. 发现不使用复杂的 VAD 逻辑，仅简单静音超时切分就能获得较完整的转录，但幻觉也会增多（看起来难以处理复杂场景，需要进一步研究） => 已经实现一种基于静音超时的截断逻辑（在静音段的中间折断），效果较好，但幻觉仍然存在